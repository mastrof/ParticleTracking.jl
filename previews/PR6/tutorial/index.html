<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · ParticleTracking.jl</title><meta name="title" content="Tutorial · ParticleTracking.jl"/><meta property="og:title" content="Tutorial · ParticleTracking.jl"/><meta property="twitter:title" content="Tutorial · ParticleTracking.jl"/><meta name="description" content="Documentation for ParticleTracking.jl."/><meta property="og:description" content="Documentation for ParticleTracking.jl."/><meta property="twitter:description" content="Documentation for ParticleTracking.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ParticleTracking.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Tutorial</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mastrof/ParticleTracking.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mastrof/ParticleTracking.jl/blob/main/docs/src/tutorial.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial"><a class="docs-heading-anchor" href="#Tutorial">Tutorial</a><a id="Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorial" title="Permalink"></a></h1><p>We will use a sample video to test detection and tracking. The video is available here: [xxx]; we will load it with the Download.jl package. We will walk through the entire pipeline, showcasing most of the package features and how to use them to get the best tracking results.</p><p>It is already preprocessed. For convenience, we want to convert the pixel values to Float16 or Float32 values, and normalize these values in the range [0,1].</p><p>The entire dataset, a three-dimensional array, can be visualized in the form of a volume plot where the <code>x</code> and <code>y</code> axis correspond to the two axes of each image, and the vertical <code>z</code> axis represents time, i.e. the different frames which compose the video. With this plot, we should already be able to identify the salient features of the dataset: small bright objects moving in the xy plane. Our task is to algorithmically select all the points corresponding to &quot;real&quot; moving objects, and connect their positions over time.</p><p>At a glance, it should be easy to recognize some straight vertical streaks, corresponding to objects which are barely moving in the xy plane, and then 2 clouds of scattered points, corresponding to objects that are actually moving.</p><pre><code class="language- hljs">using Downloads, TiffImages, CairoMakie
fpath = joinpath(pwd(), &quot;sample_video.tif&quot;)
Downloads.download(
    &quot;https://github.com/mastrof/ParticleTracking.jl/raw/docs/docs/src/sample_video.tif&quot;,
    fpath
)
video = TiffImages.load(fpath) .|&gt; Float16
rm(fpath) ## clean up after loading the video
video .-= minimum(video)
video ./= maximum(video)
volume(video)</code></pre><p>Before performing the full detection, we can explore the data to find the optimal parameters.</p><p>An interactive GUI is provided through GLMakie with the <code>gui_blobs</code> function. In the large main window we see one frame of the video, with the detected blobs surrounded by red circles. We can manipulate the <code>size</code> of the blobs we want to detect and set an amplitude <code>threshold</code> to filter out spurious low-intensity spots which are wrongly detected as objects. We can also zoom in and move the image around, as well as check the quality of the detection on different frames.</p><p>On the side, we see a scatter plot showing the zeroth (<code>m₀</code>) and second (<code>m₂</code>) intensity moments of the detected blobs (using a batch of 20 frames to provide some meaningful statistics). The values of these moments can be used for further filtering or discrimination.</p><p>gui_blobs(video)</p><p>After exploring, we can set the desired parameters and actually perform the detection. We will limit the blob sizes between 2 to 4 pixels, and set the intensity threshold to 0.05.</p><p>The detection is performed with the <code>detect_blobs</code> function, which has to be applied individually to each frame of <code>video</code>.</p><pre><code class="language- hljs">using ParticleTracking

blobsize = 2:4
rthresh = 0.05
blobs = [detect_blobs(img, blobsize; rthresh) for img in eachslice(video; dims=3)]</code></pre><p><code>blobs</code> is a vector where each element corresponds to a single frame of <code>video</code>. Each element is itself a vector of <code>Blob</code>s, an object which contains all the information about the blob; its position in the image, its size and other properties. The <code>Blob</code> API is described <a href="XXX">here</a>.</p><p>A typical step after the initial detection is to look at the zeroth and second intensity moments of the blobs, which can provide information about differences between the detected objects.</p><pre><code class="language- hljs">m0 = map.(zeroth_moment, blobs)
m2 = map.(second_moment, blobs)
scatter(vcat(m0...), vcat(m2...); alpha=0.5, axis=(xlabel=&quot;m0&quot;, ylabel=&quot;m2&quot;))</code></pre><p>The zeroth moment (<code>m0</code>) is proportional to the total intensity of the blob; the tight cluster in the bottom left (<code>0.5&lt;m0&lt;0.7</code> and <code>1.6&lt;m2&lt;1.7</code>), which is well separated from the rest of the datapoints, is then likely to identify spurious detections resulting from pixel shot noise. If this is the case, it would be good to filter out these blobs before moving on to the tracking. A clean set of blobs without spurious detections can drastically improve the tracking quality, but excessive filtering can have the opposite effects.</p><p>To verify our hypothesis, i.e., low-<code>m0</code> low-<code>m2</code> blobs are spurious detections, we have to visually check what these blobs correspond to in the image. We can then separate the two populations and highlight them in the images with different colors.</p><pre><code class="language- hljs">maybe_spurious = [
    findall(@. (0.5 &lt; m0[i] &lt; 0.7) &amp;&amp; (1.6 &lt; m2[i] &lt; 1.7))
    for i in eachindex(blobs)
]
A = @. view(blobs, maybe_spurious)
B = @. view(blobs, setdiff(eachindex(blobs), maybe_spurious))

# visualize the two populations in frame t
let t = 1
    fig, ax, = heatmap(video[:,:,t], colormap=:bone)
    # blobs can be directly plotted in Makie with scatter
    scatter!(ax, A[t], color=:red, alpha=0.1, markersize=30)
    scatter!(ax, B[t], color=:green, alpha=0.1, markersize=30)
    fig
end</code></pre><p>The red marker (as can be confirmed by trying different frames <code>t</code>), is always associated to a specific object in the image, but we clearly see it as quite bright! Why is it different from the others then? By zooming in, we can see that it is a <em>single</em> bright pixel, whereas the other blobs, while still extremely small, correspond to a larger bright area.</p><p>It turns out that the camera I used to collect this video has a dead pixel, which is always showing up as illuminated. That is what our moments-based filtering has allowed us to identify.</p><p>It is also possible to directly access the <code>intensity_map</code> of a blob, i.e. the set of pixels which have been identified as a unique blob. We can, for instance, plot the intensity_map of this spurious blob along side that of another blob (<code>j</code>) in the other population. We see that &quot;real&quot; blobs are generally brighter and/or more extended than the spurious one.</p><pre><code class="language- hljs">let t=1, I_A=intensity_map(A[t][1]), j=1, I_B=intensity_map(B[t][j])
    M = max(maximum(I_A), maximum(I_B))
    fig, ax1 = heatmap(I_A; colorrange=(0,M), axis=(title=&quot;Spurious&quot;,))
    ax2 = Axis(fig[1,2], title=&quot;Real&quot;)
    heatmap!(ax2, I_B; colorrange=(0,M))
    fig
end</code></pre><p>Now we can safely filter out the spurious detections and move on to the tracking using the <code>blobtracking</code> function.</p><p>In principle, we don&#39;t need to do anything special and we can just call <code>blobtracking(blobs)</code>, but we will see the results are much less than optimal.</p><pre><code class="language- hljs"># reassign blobs to the subpopulation without spurious detections
blobs = deepcopy(B)
# do the tracking
trajectories = blobtracking(blobs)
# visualize plotting trajectories one by one
let
    fig = Figure()
    ax = Axis(fig[1,1])
    for track in trajectories
        lines!(ax, track)
    end
    fig
end</code></pre><p>We see that the algorithm tends to connect points that are far away from each other. Indeed, since the tracking is based on finding the &quot;minimum cost flow&quot; between successive frames, it always tries to connect points in order to not interrupt any trajectory. This leads, however, to unreasonable connections. The first thing to do, therefore, is to define the maximum distance that an object can cover during a single frame: any connection between points at a distance larger than this threshold will be less favorable than to just interrupt the trajectory.</p><p>The maximum distance can be set through the <code>maxdist</code> keyword. In our case, after visual inspection it seems reasonable to set this limit to 60 pixels</p><pre><code class="language- hljs">maxdist = 60
trajectories = blobtracking(blobs; maxdist)
let
    fig = Figure()
    ax = Axis(fig[1,1])
    for track in trajectories
        lines!(ax, track)
    end
    fig
end</code></pre><p>This is already much better. But we can do more.</p><pre><code class="language- hljs">scatter(length.(trajectories))</code></pre><p>A quick look at the length of the trajectories we obtained shows that we have a few very long trajectories (basically spanning the entire video) a few medium-length ones and then a bunch of trajectories only 1-frame long.</p><p>A 1-frame trajectory is basically a blob that has been detected but not connected to anything. This can happen for various reasons. If it&#39;s spurious detections that survived our filtering but didn&#39;t produce any connection, that&#39;s perfect, we will just filter these trajectories out. But they may also be real objects which, somehow, were not consistently detected across successive frames and hence did not produce a trajectory.</p><p>In fact, our algorithm has been only looking at immediately successive frames, but we can also account for the fact that an object might disappear from the field of view for a few frames, and that we may still be able to recognize it if it appears again.</p><p>Connections across frame gaps are controlled by the <code>memory</code> keyword. By default it is set to 1, meaning that only the immediate next frame is investigated for a connection. But increasing its value allows us to close gaps due to objects disappearing from the field of view. Allowing too much <code>memory</code> will, however, have detrimental effects: the objects are allowed to travel <code>maxdist</code> <em>every frame</em>, therefore large <code>memory</code> values will allow connections between objects far away in space and time.</p><pre><code class="language- hljs">maxdist = 60
memory = 5
trajectories = blobtracking(blobs; maxdist, memory)
let
    fig = Figure()
    ax = Axis(fig[1,1])
    for track in trajectories
        lines!(ax, track)
    end
    fig
end</code></pre><p>Compared to the previous memoryless trial, the pink trajectory in the bottom has been extended; the three nearby blue, green, light-blue segments now constitute a single, longer trajectory; the two orange and pink trajectories at the top are now joined into a single one; the brownian trajectories on the left have not been modified since they were already optimal.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Monday 8 January 2024 17:18">Monday 8 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
